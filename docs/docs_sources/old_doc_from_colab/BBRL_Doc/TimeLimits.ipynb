{"cells":[{"cell_type":"markdown","metadata":{"id":"dYfGJCe52lP4"},"source":["# Outlook"]},{"cell_type":"markdown","metadata":{"id":"aZUSf0n_2otG"},"source":["In this notebook we explain how to properly deal with time limits when interacting with a gym environment."]},{"cell_type":"markdown","source":["## Dealing with time limits"],"metadata":{"id":"AtKPR25b288G"}},{"cell_type":"markdown","source":["A lot of RL problems are episodic: the agent must achieve a task and when this is done, the episode stops. To deal with the case where the agent does not succeed and to accelerate learning, it is standard for these episodic problems to come with a time limit: if the agent did not succeed after a number of time steps, the episode stops."],"metadata":{"id":"PtFXRZRj3dGp"}},{"cell_type":"markdown","source":["As explained in [this paper](http://proceedings.mlr.press/v80/pardo18a/pardo18a.pdf), this situation is a source of instability in RL, as it creates some non-stationarity in the underlying MDP. The point is that, in the same state, the agent may either continue and receive some later reward, or get stopped by the time limit and receive nothing."],"metadata":{"id":"jX4OjoyWrXM7"}},{"cell_type":"markdown","source":["The proper way to deal with time limits consists in still propagating values in the critic from the next state to the current state (a Bellman backup) over the last transition when the episode is stopped by a time limit, by contrast with the case where the episode stops because the task is done, in which case the value of the next state should be ignored."],"metadata":{"id":"NXplGF5FsRns"}},{"cell_type":"markdown","source":["In gym environments, the variable `done` is set to True when the task is done, but also when the time limit is reached. To distinguish the latter case, the `TimeLimit` wrapper sets the `TimeLimit.Truncated` to True when the time limit is reached and the task is not done, and to False when the time limit is reached AND the task is done simultaneously. This is not much intuitive, but that's how it is..."],"metadata":{"id":"My54maoNmZDY"}},{"cell_type":"markdown","source":["So the rules to apply when an episode stops are the following:\n","- if `TimeLimit.Truncated` is True, the episode should be bootstrapped whatever the value of done,\n","- otherwise, and if the task is done, the Bellman backup should be ignored."],"metadata":{"id":"yWsMaRPftPLd"}},{"cell_type":"markdown","source":["To implement the above, rather than using a complicated \"if... then... \" set of rules, we compute a boolean `must_bootstrap` determining whether the value of the next state should be bootstrapped or not, and then we multiply the value of the next state by this boolean (that is, 1 if the boolean is true, 0 otherwise). This results in the following piece of code:"],"metadata":{"id":"pINE0XUst3Rr"}},{"cell_type":"code","source":["done = train_workspace[\"env/done\"]\n","truncated = (train_workspace[\"env/timestep\"] == max_episode_steps)\n","must_bootstrap = torch.logical_or(~done, truncated)\n","\n","# In the line below, reward[:-1] means \"the reward of all steps but the last one\"\n","# and critic[1:] means the values of the critic at the next state\n","target = reward[:-1] + discount_factor * critic[1:].detach() * (must_bootstrap.float())\n","td = target - critic[:-1]"],"metadata":{"id":"f966W_Qgt8eF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that `reward[:-1]` stands for \"all the rewards but the last one\", whereas `critic[1:]` stands for \"all the critic values but the first one\", which in the context of pairs respectively mean all values of $r_t$ and $V(s_{t+1})$."],"metadata":{"id":"mSJko7Van8Qj"}},{"cell_type":"markdown","source":["Note also the `critic[1:].detach()`: the gradient is computed with respect to $V(s_t)$ but not with respect to $V(s_{t+1})$."],"metadata":{"id":"ezSbwjXvflIR"}},{"cell_type":"markdown","source":["Finally, note that if the environment is wrapped into several time limit wrappers, the `TimeLimit.Truncated` variable does not work properly, even if the various time limits are the same number of steps. So one should avoid put a TimeLimit wrapper around an environment that already contains one."],"metadata":{"id":"albjNrrOzs5d"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"TimeLimits.ipynb","provenance":[{"file_id":"1W9Y-3fa6LsPeR6cBC1vgwBjKfgMwZvP5","timestamp":1654844990669},{"file_id":"1Ui481r47fNHCQsQfKwdoNEVrEiqAEokh","timestamp":1651727382606},{"file_id":"1yAQlrShysj4Q9EBpYM8pBsp2aXInhP7x","timestamp":1650560438416},{"file_id":"1XUJSplQm_MttDKtzsJ1AKhhJQT_W0oWi","timestamp":1650557706114},{"file_id":"1J74foctf26QfZ4DuKxGfAwrO2wZmedNi","timestamp":1643612886194},{"file_id":"1-aidxjij0JwVyOgYSLqR-v4KMow4BsbQ","timestamp":1641470409971},{"file_id":"1tZ744yXYoDhwk0xk73baYa7Ks4MRpba8","timestamp":1641465913520},{"file_id":"1SEFpe1yUMjUsKzYkqWF_xQzVzZOQutHZ","timestamp":1641289551712}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}