{"cells":[{"cell_type":"markdown","source":["## Creating a deterministic critic agent"],"metadata":{"id":"AtKPR25b288G"}},{"cell_type":"markdown","source":["The function below builds a multi-layer perceptron where the size of each layer is given in the `size` list. We also specify the activation function of neurons at each layer and optionally a different activation function for the final layer."],"metadata":{"id":"l_LkwKoEMPsX"}},{"cell_type":"code","source":["def build_mlp(sizes, activation, output_activation=nn.Identity()):\n","    layers = []\n","    for j in range(len(sizes) - 1):\n","        act = activation if j < len(sizes) - 2 else output_activation\n","        layers += [nn.Linear(sizes[j], sizes[j + 1]), act]\n","    return nn.Sequential(*layers)"],"metadata":{"id":"kOmwets4LZub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `DiscreteQAgent` class implements a critic such the one used in DQN. It has one output neuron per action and its output is the Q-value of these actions given the state."],"metadata":{"id":"6u8r5T5sMppN"}},{"cell_type":"markdown","source":["As any BBRL agent, it has a forward function that takes a time state as input. This forward function outputs the Q-values at the corresponding time step. Additionally, if the critic is used to choose an action, it also outputs the chosen action at the same time step."],"metadata":{"id":"T_Rj1SZrNB6E"}},{"cell_type":"code","source":["class DiscreteQAgent(Agent):\n","    def __init__(self, state_dim, hidden_layers, action_dim):\n","        super().__init__()\n","        self.is_q_function = True\n","        self.model = build_mlp(\n","            [state_dim] + list(hidden_layers) + [action_dim], activation=nn.ReLU()\n","        )\n","\n","    def forward(self, t, choose_action=True, **kwargs):\n","        obs = self.get((\"env/env_obs\", t))\n","        q_values = self.model(obs).squeeze(-1)\n","        self.set((\"q_values\", t), q_values)\n","        if choose_action:\n","            action = q_values.argmax(1)\n","            self.set((\"action\", t), action)\n"],"metadata":{"id":"O4u_vhwjLIfM"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1yAQlrShysj4Q9EBpYM8pBsp2aXInhP7x","timestamp":1650560438416},{"file_id":"1XUJSplQm_MttDKtzsJ1AKhhJQT_W0oWi","timestamp":1650557706114},{"file_id":"1J74foctf26QfZ4DuKxGfAwrO2wZmedNi","timestamp":1643612886194},{"file_id":"1-aidxjij0JwVyOgYSLqR-v4KMow4BsbQ","timestamp":1641470409971},{"file_id":"1tZ744yXYoDhwk0xk73baYa7Ks4MRpba8","timestamp":1641465913520},{"file_id":"1SEFpe1yUMjUsKzYkqWF_xQzVzZOQutHZ","timestamp":1641289551712}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}