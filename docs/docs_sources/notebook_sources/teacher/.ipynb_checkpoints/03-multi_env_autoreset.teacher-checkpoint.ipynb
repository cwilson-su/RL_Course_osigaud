{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad662f0e",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "This notebook is designed to understand how to use a gymnasium environment as a BBRL agent in practice, using autoreset=True.\n",
    "It is part of the [BBRL documentation](https://github.com/osigaud/bbrl/docs/index.html).\n",
    "\n",
    "If this is your first contact with BBRL, you may start be having a look at [this more basic notebook](01-basic_concepts.student.ipynb) and [the one using autoreset=False](02-multi_env_noautoreset.student.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be9cf1",
   "metadata": {},
   "source": [
    "## Installation and Imports\n",
    "\n",
    "The BBRL library is [here](https://github.com/osigaud/bbrl).\n",
    "\n",
    "Below, we import standard python packages, pytorch packages and gymnasium environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841b855f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[easypip] Installing bbrl_gymnasium>=0.2.0\n",
      "[easypip] Installing bbrl_gymnasium[classic_control]\n"
     ]
    }
   ],
   "source": [
    "# Installs the necessary Python and system libraries\n",
    "try:\n",
    "    from easypip import easyimport, easyinstall, is_notebook\n",
    "except ModuleNotFoundError as e:\n",
    "    get_ipython().run_line_magic(\"pip\", \"install easypip\")\n",
    "    from easypip import easyimport, easyinstall, is_notebook\n",
    "\n",
    "easyinstall(\"bbrl>=0.2.2\")\n",
    "easyinstall(\"swig\")\n",
    "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
    "easyinstall(\"bbrl_gymnasium[classic_control]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38dd858c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "from moviepy.editor import ipython_display as video_display\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import bbrl_gymnasium\n",
    "\n",
    "import copy\n",
    "from abc import abstractmethod, ABC\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import strftime\n",
    "OmegaConf.register_new_resolver(\n",
    "    \"current_time\", lambda: strftime(\"%Y%m%d-%H%M%S\"), replace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e43c7e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports all the necessary classes and functions from BBRL\n",
    "from bbrl.agents.agent import Agent\n",
    "from bbrl import get_arguments, get_class, instantiate_class\n",
    "# The workspace is the main class in BBRL, this is where all data is collected and stored\n",
    "from bbrl.workspace import Workspace\n",
    "\n",
    "# Agents(agent1, agent2, agent3, ...) executes the different agents the one after the other\n",
    "# TemporalAgent(agent) executes an agent over multiple timesteps in the workspace, \n",
    "# or until a given condition is reached\n",
    "\n",
    "from bbrl.agents import Agents, TemporalAgent\n",
    "from bbrl.agents.gymnasium import ParallelGymAgent, make_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59585ceb",
   "metadata": {},
   "source": [
    "## Definition of agents\n",
    "\n",
    "As before, we first create an Agent representing [the CartPole-v1 gym environment](https://gymnasium.farama.org/environments/classic_control/cart_pole/).\n",
    "This is done using the [ParallelGymAgent](https://github.com/osigaud/bbrl/blob/40fe0468feb8998e62c3cd6bb3a575fef88e256f/src/bbrl/agents/gymnasium.py#L261) class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665614f",
   "metadata": {},
   "source": [
    "## Single environment case\n",
    "\n",
    "We start with a Random Agent and a single instance of the CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f6eb4b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: observation space in R^4 and action space R^2\n"
     ]
    }
   ],
   "source": [
    "# We deal with 1 environment at a time (random seed 2139)\n",
    "\n",
    "env_agent = ParallelGymAgent(partial(make_env, env_name='CartPole-v1'), 1).seed(2139)\n",
    "obs_size, action_dim = env_agent.get_obs_and_actions_sizes()\n",
    "print(f\"Environment: observation space in R^{obs_size} and action space R^{action_dim}\")\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def __init__(self, action_dim):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def forward(self, t: int, choose_action=True, **kwargs):\n",
    "        \"\"\"An Agent can use self.workspace\"\"\"\n",
    "        obs = self.get((\"env/env_obs\", t))\n",
    "        action = torch.randint(0, self.action_dim, (len(obs), ))\n",
    "        self.set((\"action\", t), action)\n",
    "\n",
    "# Each agent will be run (in the order given when constructing Agents)\n",
    "agents = Agents(env_agent, RandomAgent(action_dim))\n",
    "t_agents = TemporalAgent(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccdd33",
   "metadata": {},
   "source": [
    "Let us have a closer look at the content of the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f338bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observations (first 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0471,  0.0265,  0.0220, -0.0336],\n",
       "        [-0.0466, -0.1689,  0.0214,  0.2660],\n",
       "        [-0.0500, -0.3643,  0.0267,  0.5653]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Transitions of actions (first 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'(s_0, s_1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0471,  0.0265,  0.0220, -0.0336],\n",
       "        [-0.0466, -0.1689,  0.0214,  0.2660]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'(s_1, s_2)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0466, -0.1689,  0.0214,  0.2660],\n",
       "        [-0.0500, -0.3643,  0.0267,  0.5653]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'(s_2, s_3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0500, -0.3643,  0.0267,  0.5653],\n",
       "        [-0.0572, -0.1696,  0.0380,  0.2812]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates a new workspace\n",
    "workspace = Workspace() \n",
    "t_agents(workspace, stop_variable=\"env/done\")\n",
    "\n",
    "# We get the transitions: each tensor is transformed so\n",
    "# that: \n",
    "# - we have the value at time step t and t+1 (so all the tensors first dimension have a size of 2)\n",
    "# - there is no distinction between the different environments (here, there is just one environment run in parallel to make it easy)\n",
    "transitions = workspace.get_transitions()\n",
    "\n",
    "# You can see that each pair of actions in the transitions can be found in the workspace\n",
    "display(\"Observations (first 3)\", workspace[\"env/env_obs\"][:3, 0])\n",
    "\n",
    "display(\"Transitions of actions (first 3)\")\n",
    "for t in range(3):\n",
    "    display(f'(s_{t}, s_{t+1})')\n",
    "    display(transitions[\"env/env_obs\"][:, t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618133d6",
   "metadata": {},
   "source": [
    "## Multiple environment case\n",
    "\n",
    "Now we are using 3 environments.\n",
    "Given the organization of transitions, to find the transitions of a particular environment\n",
    "we have to watch in the transition every 3 lines, since transitions are stored one environment after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f8490",
   "metadata": {},
   "source": [
    "## The replay buffer\n",
    "\n",
    "Differently from the previous case, we use a replace buffer that stores\n",
    "a set of transitions $(s_t, a_t, r_t, s_{t+1})$\n",
    "Finally, the replay buffer keeps slices [:, i, ...] of the transition\n",
    "workspace (here at most 100 transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ec6e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReplayBuffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rb \u001b[38;5;241m=\u001b[39m \u001b[43mReplayBuffer\u001b[49m(max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# We add the transitions to the buffer....\u001b[39;00m\n\u001b[1;32m      4\u001b[0m rb\u001b[38;5;241m.\u001b[39mput(transitions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReplayBuffer' is not defined"
     ]
    }
   ],
   "source": [
    "rb = ReplayBuffer(max_size=100)\n",
    "\n",
    "# We add the transitions to the buffer....\n",
    "rb.put(transitions)\n",
    "\n",
    "# And sample from them here we get 3 tuples (s_t, s_{t+1})\n",
    "rb.get_shuffled(3)[\"env/env_obs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d7c96",
   "metadata": {},
   "source": [
    "A transition workspace is still a workspace... this is quite\n",
    " handy since each transition can be seen as a mini-episode of two time steps;\n",
    " we can use our agents on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a390d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as a reference\n",
    "\n",
    "display(transitions[\"action\"])\n",
    "\n",
    "t_random_agent = TemporalAgent(RandomAgent(action_dim))\n",
    "t_random_agent(transitions, t=0, n_steps=2)\n",
    "\n",
    "# Here, the action tensor will have been overwritten by the new actions\n",
    "display(transitions[\"action\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
